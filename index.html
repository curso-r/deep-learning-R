<!DOCTYPE html>
<html>
  <head>
    <title>Deep Learning e R</title>
    <meta charset="utf-8">
    <meta name="author" content="Daniel Falbel (@Curso-R)   dfalbel@curso-r.com" />
    <meta name="date" content="2018-08-06" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Deep Learning e R
### Daniel Falbel (<span class="citation">@Curso-R</span>) <br> <a href="mailto:dfalbel@curso-r.com">dfalbel@curso-r.com</a>
### 08/06/2018

---




## Oi!

- Bacharel em Estatística (2015)

- Sócio da [Curso-R](http://curso-r.com)

- Sócio da [R6](http://rseis.com.br)

---

## TensorFlow

É uma biblioteca geral de computação numérica.

- Desenvolvida dentro da Google Brain para pesquisas em Redes Neurais
- Open Source
- Diferencição Automática

![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/AutomaticDifferentiationNutshell.png/1280px-AutomaticDifferentiationNutshell.png)

---

## Tensores

(2d)


```r
head(data.matrix(iris), 10)
```

```
##       Sepal.Length Sepal.Width Petal.Length Petal.Width Species
##  [1,]          5.1         3.5          1.4         0.2       1
##  [2,]          4.9         3.0          1.4         0.2       1
##  [3,]          4.7         3.2          1.3         0.2       1
##  [4,]          4.6         3.1          1.5         0.2       1
##  [5,]          5.0         3.6          1.4         0.2       1
##  [6,]          5.4         3.9          1.7         0.4       1
##  [7,]          4.6         3.4          1.4         0.3       1
##  [8,]          5.0         3.4          1.5         0.2       1
##  [9,]          4.4         2.9          1.4         0.2       1
## [10,]          4.9         3.1          1.5         0.1       1
```

---


## Tensores 

(3d)

![:scale 50%](3d-tensor.png)

---

## Tensores 

(4d)

![:scale 50%](4d-tensor.png)

---

## TensorFlow

.pull-left[
  ![](flow.gif)
]

.pull-right[
  - Definimos o grafo
  - o Grafo é compilado e otimizado
  - O grafo é executado
  - Os nós representam cálculos
  - Os tensores *fluem* entre os nós.
]

---

## Keras

* Uma API que permite especificar modelos de *Deep Learning* de forma intuitiva e rápida.

* Criada por François Chollet (@fchollet).

![:scale 40%](https://pbs.twimg.com/profile_images/831025272589676544/3g6BrXCE_400x400.jpg)

* Originalmente implementada em `python`.

---

## Keras

* Uma API com múltiplas implementações.

![](keras.svg)&lt;!-- --&gt;

---

## Keras + R

* Pacote do R: [`keras`](https://github.com/rstudio/keras).

* Baseado em [reticulate](https://github.com/rstudio/reticulate).

* Desenvolvido pelo JJ Allaire (CEO do RStudio).

* Tem uma sintaxe R-like com uso de `%&gt;%`.

![:scale 70%](https://i.ytimg.com/vi/D8yF9AtTTuQ/maxresdefault.jpg)

---
class: inverse, middle, center

## Exemplo

### [Classifying duplicate questions from Quora with Keras](https://tensorflow.rstudio.com/blog/keras-duplicate-questions-quora.html)

---

![:scale 50%](https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Quora_logo_2015.svg/2000px-Quora_logo_2015.svg.png)

* [Quora](https://www.quora.com): site de perguntas e respostas de âmbito geral.

* Para quem usa o Quora, é melhor ter apenas uma versão de uma pergunta.

* Banco de dados de uma [competição do Kaggle](https://www.kaggle.com/c/quora-question-pairs).

* ~400k pares de perguntas duplicadas (ou não) marcadas pelos moderadores do site.

* **Objetivo:** Identificar os pares de perguntas que possuem o mesmo _significado_.

* Antes da competição o problema era resolvido com Random Forests, depois passaram a usar [Deep Learning](https://engineering.quora.com/Semantic-Question-Matching-with-Deep-Learning).

---

### Duplicadas

&lt;div&gt;
.pull-left[
  * How can I be a good geologist?
  
  
  * How do I read and find my YouTube comments? 
  
  * What can make Physics easy to learn?  
]

.pull-right[
  - What should I do to be a great geologist? 
  
  
  - How can I see all my Youtube comments?
  
  - How can you make physics easy to learn? 
]
&lt;/div&gt;


### Não-Duplicadas

&lt;div&gt;
.pull-left[
  * How can I increase the speed of my internet connection while using a VPN?	
  
  
  * What is the step by step guide to invest in share market in india?
  
  * How do I get over my ex's past?	

]

.pull-right[
  * How can Internet speed be increased by hacking through DNS?
  
  
  * What is the step by step guide to invest in share market?
  
  * What is the best way to get over your ex?	
]
&lt;/div&gt;

---

## Arquitetura do modelo

&lt;br&gt;
&lt;br&gt;

![](modelo-esquema.svg)&lt;!-- --&gt;

* Siamese LSTM

---

#### Embedding

![](embedding.svg)&lt;!-- --&gt;

---

## LSTM

![](lstm.svg)&lt;!-- --&gt;

---

## LSTM


![](https://mlalgorithm.files.wordpress.com/2016/08/rnn1.jpg?w=571&amp;h=283)

---

## Arquitetura no Keras

&lt;br&gt;
&lt;br&gt;

![](modelo-keras.svg)&lt;!-- --&gt;

---

## Código


```r
library(keras)
```

--


```r
input1 &lt;- layer_input(shape = c(20), name = "input_question1")
input2 &lt;- layer_input(shape = c(20), name = "input_question2")
```

--


```r
word_embedder &lt;- layer_embedding( 
  input_dim = 50000,     # vocab size 
  output_dim = 128,      # hyperparameter - embedding size
  input_length = 20     # padding size
)
```

--


```r
seq_embedder &lt;- layer_lstm(units = 128)
```

--


```r
vector1 &lt;- input1 %&gt;% word_embedder() %&gt;% seq_embedder()
vector2 &lt;- input2 %&gt;% word_embedder() %&gt;% seq_embedder()
```

--


```r
#&gt; Tensor("lstm_1/TensorArrayReadV3:0", shape=(?, 128), dtype=float32)
#&gt; Tensor("lstm_1_1/TensorArrayReadV3:0", shape=(?, 128), dtype=float32)
```

---

## Arquitetura do Modelo

&lt;br&gt;
&lt;br&gt;

![](modelo-keras.svg)&lt;!-- --&gt;

---

## Código


```r
cosine_similarity &lt;- layer_dot(list(vector1, vector2), axes = 1)
```

--


```r
output &lt;- cosine_similarity %&gt;% 
  layer_dense(units = 1, activation = "sigmoid")
```

--


```r
model &lt;- keras_model(list(input1, input2), output)
model %&gt;% compile(
  optimizer = "adam", 
  metrics = list(acc = metric_binary_accuracy), 
  loss = "binary_crossentropy"
)
```

---


```r
summary(model)
```


```r
# _______________________________________________________________________________________
# Layer (type)                Output Shape       Param #    Connected to                 
# =======================================================================================
# input_question1 (InputLayer (None, 20)         0                                       
# _______________________________________________________________________________________
# input_question2 (InputLayer (None, 20)         0                                       
# _______________________________________________________________________________________
# embedding_1 (Embedding)     (None, 20, 128)    6400256    input_question1[0][0]        
#                                                           input_question2[0][0]        
# _______________________________________________________________________________________
# lstm_1 (LSTM)               (None, 128)        131584     embedding_1[0][0]            
#                                                           embedding_1[1][0]            
# _______________________________________________________________________________________
# dot_1 (Dot)                 (None, 1)          0          lstm_1[0][0]                 
#                                                           lstm_1[1][0]                 
# _______________________________________________________________________________________
# dense_1 (Dense)             (None, 1)          2          dot_1[0][0]                  
# =======================================================================================
# Total params: 6,531,842
# Trainable params: 6,531,842
# Non-trainable params: 0
# _______________________________________________________________________________________
```

---

## Treinando


```r
model %&gt;% fit(
  list(train_question1_padded, train_question2_padded),
  train_is_duplicate, 
  batch_size = 64, 
  epochs = 10, 
  validation_data = list(
    list(val_question1_padded, val_question2_padded), 
    val_is_duplicate
  )
)
```


```r
# Train on 363861 samples, validate on 40429 samples
# Epoch 1/10
# 363861/363861 [==============================] - 89s 245us/step - loss: 0.5860 - acc: 0.7248 - val_loss: 0.5590 - val_acc: 0.7449
# Epoch 2/10
# 363861/363861 [==============================] - 88s 243us/step - loss: 0.5528 - acc: 0.7461 - val_loss: 0.5472 - val_acc: 0.7510
# Epoch 3/10
# 363861/363861 [==============================] - 88s 242us/step - loss: 0.5428 - acc: 0.7536 - val_loss: 0.5439 - val_acc: 0.7515
```

---

## Algumas aplicações

### [Show and Tell](https://ai.googleblog.com/2016/09/show-and-tell-image-captioning-open.html)


![](https://1.bp.blogspot.com/-gmCkHgRKbp0/V-L9sTZuevI/AAAAAAAABPE/0Im_E8pWqGoS3eC90DpYHS17vuFgLBh5gCLcB/s640/Caption3c.png)

---

### [Zero Shot Translation](https://ai.googleblog.com/2016/11/zero-shot-translation-with-googles.html)

![](https://1.bp.blogspot.com/-jwgtcgkgG2o/WDSBrwu9jeI/AAAAAAAABbM/2Eobq-N9_nYeAdeH-sB_NZGbhyoSWgReACLcB/s640/image01.gif)

---

### [Speech Generation](https://google.github.io/tacotron/publications/tacotron2/index.html)

![](https://3.bp.blogspot.com/-0TuzPYkfecA/WlaSABCyRnI/AAAAAAAACTo/Z41PW_uqHsAiw6ZydxPO5pyDnU5ft8K6wCLcBGAs/s640/image11.png)

---

### [The Case for Learned Index Structures](https://arxiv.org/abs/1712.01208)

![](https://1.bp.blogspot.com/-5jKNnxvbamI/WlaSQr08plI/AAAAAAAACTw/Tq68VrmBqqcg1QDEMlj4oGn_MMTOCV8UgCLcBGAs/s640/image5.png)

---

## Discussão: Por que nós estatísticos ligamos para Deep Learning?

Novos problemas:

- Visão computacional
- Reconhecimento de fala

Melhorar em alguns problemas tradicionais?

- Analisar dados de sequeências complexas
- Analisar dados espaciais
- ? 

---

## Mais

* [Galeria de exemplos do Keras](https://keras.rstudio.com/articles/examples/index.html).
* [Livro: Deep Learning com R](https://www.amazon.com/Deep-Learning-R-Francois-Chollet/dp/161729554X)
* [Blog: Tensorflow for R](https://tensorflow.rstudio.com/blog.html)
* [Deep Learning Book](http://www.deeplearningbook.org)

![](https://naweb.files.wordpress.com/2012/04/gato-lendo-livroa.gif)

---
class: inverse, middle, center

## Obrigado

dfalbel@curso-r.com

github.com/dfalbel
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="js/macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
